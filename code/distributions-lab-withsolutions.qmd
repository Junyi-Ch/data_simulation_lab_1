---
title: "Simulations & Tidyverse lab: With solutions"
subtitle: "Psych 201a"
author: "Bria Long"
date: "`r format(Sys.Date())`"
format:
  html:
    toc: true
    toc-depth: 2
    theme: cosmo
  pdf: default
execute:
  echo: true
  warning: false
  message: false
editor: visual
---

> **Goals:** (1) Understand how normal, binomial, and lognormal distributions describe behavioral data (accuracy, RTs, individual variability). (2) Practice generating and visualizing synthetic datasets using tidyverse functions. (3) Learn how to write reproducible lab reports with inline statistics in Quarto.

> **Workflow:** Copy the worked example, then complete tasks using tidyverse verbs. Keep your write-up reproducible using **inline R**.

## Setup

```{r}
#| label: setup
library(tidyverse)
set.seed(2025)

```

## A. Normal distribution (worked example)

Here, let's try to simulate some values from a normal distribution with a mean of 0 and a SD of 1.

The `rnorm` function is used below here.

```{r}

# you can play around with these
n <- 300 # number of datapoints
mu <- 0 # mean of the distribution
sd_norm <- 1 # sd of the distribution

# rnorm is your simulation function here
# take a look at how it's used by typing ``? rnorm``
## note that this function is taking the inputs you specified above -- it doesn't matter what these are called
norm_df <- tibble(sim_values = rnorm(n, mu, sd_norm))

# so you know, this code would do the same thing
# norm_df <- tibble(sim_values = rnorm(300, 0, 1))

# okay, check out the top of this dataframe
head(norm_df)
```

Calculate some basic summaries of this dataframe and print them out

```{r}
norm_df_summary<- norm_df |> 
  summarise(mean = mean(sim_values), sd = sd(sim_values), n = n())

print(norm_df_summary)

# What happens if you increase the "n"? How do these summaries change?
```

I'm going to now plot a histogram of these values. We're going to spend a lot of time on figuring out how to plot things late -- but here you can start learning the basics

The first argument to the ggplot function is your dataframe -- here, `norm_df`. The `aes` is where you specify what is on the x-axis, y-axis, colors, etc. These values come from the columns in `norm_df`

`Alpha` is tranparency. `bindwidth` is how big the histogram bins are.

```{r}
ggplot(norm_df, aes(x=sim_values)) +
  geom_histogram(binwidth = 0.25, alpha = 0.85) +
  labs(title = "Simulated values", x = "Value", y = "Count")
```

**Excercise:** change `mu` and `sd_norm` to two other combos (e.g., 10 & 2; 10 & 5).

Write one sentence with an inline mean (e.g., `r round(mean(norm_df$x), 2)`).

Bonus: Compute another kind of summary statistic on the dataset Bonus: Simulate another distribution and also plot it on the same histogram (you can make it a different color)

## B. Binomial data (accuracy)

Okay, normally distributed data is great, but often now what we're working with in practice. Often, we have accuracies or reaction times.

First, we'll think about accuracy. To do so, we'll practice `rbinom()` and how to summarize it using some tidyverse functions. You should be able to adapt the code we just worked through but with a new function --

### B1 --- Bernoulli accuracy

Tasks: - Simulate `n = 200` 0/1 outcomes with `p = 0.92` into `acc_df`. - Compute **proportion correct** and a **count table** with `count()`. - Plot overall proportion with `stat_summary()`.

```{r}
#| label: binom-bernoulli
# TODO: create a simulated dataframe using rbinom (remember, you can look at the help for the function)
acc_df <- tibble(acc = rbinom(200, size = 1, prob = 0.92))

# TODO: summarise and count
acc_df_summary <- acc_df |>
  summarise(prop_correct = mean(acc), n = n())
```

```{r}
## TO DO: Make a histogram of these values
ggplot(acc_df, aes(x=acc)) +
  geom_histogram(binwidth = 0.25, alpha = 0.85) +
  labs(title = "Simulated values", x = "Value", y = "Count")
```

```{r}
# TODO: plot overall proportion 
# Hint:  use `stat_summary(fun = mean)` for the mean

# TO DO: Plot some measure of variability (SD or 95% CI)
# Hint: stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.1) +
# You have to give stat_summary an x-value, but since there isn't really one here you can just give it a label (e.g., "overall")

ggplot(acc_df, aes(x='Overall', y = acc)) +
  stat_summary(fun = mean, geom = "point", size = 3) +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.1) +
  labs(x = NULL, y = "Proportion correct", title = "Accuracy")
```

### B2 --- Two conditions + blocks (tidy)

Tasks: - Build a tibble with `condition` in {easy, hard}, 100 trials each. - Use different probabilities (e.g., 0.97 vs 0.87). - Summarise `prop_correct` by `condition × block` and `pivot_wider()`. - Bonus: Add a `block` or `participant` factor

```{r}
#| label: binom-conditions-blocks
# TODO: simulate
acc2 <- tibble(
  condition = rep(c("easy","hard"), each = 100),
  block = rep(rep(1:4, each = 25), times = 2),
  acc = c(rbinom(100, 1, 0.97), rbinom(100, 1, 0.87))
)

# Check per-block counts
acc2 |>
  add_count(block, name = "n_block") |>
  distinct(block, n_block)

# Summaries by condition × block
acc_by_cb <- acc2 |>
  group_by(condition, block) |>
  summarise(prop_correct = mean(acc), trials = n(), .groups = "drop")

# Pivot wider
acc_wide <- acc_by_cb |>
  pivot_wider(names_from = condition, values_from = prop_correct)

# View
acc_by_cb
acc_wide
```

Inline prompt: "Overall accuracy = `r NA`. Easy = `r NA`, Hard = `r NA`." Replace NA with inline code.

## C. Reaction times (RT): shifted lognormal

RTs are famously right-skewed (ie., sometimes participants take a very long time to respond). This looks reallly different than a normal distribution. We'll use `t0 + LogNormal(μ, σ)` to approximately simulate their distribution `t0` can be thought of a "baseline" reaction time that could vary by participant.

### Simulating reaction times

Tasks: - Simulate **n = 500** RTs with `t0 = 300`, `meanlog = log(250)`, `sdlog = 0.35` into `rt_df`. - Plot a histogram and compute **mean**, **median**, **max**. - Create `log_rt = log(rt)` and compare distributions

Here's a helper function to create lognormal RTs with a baseline shift. Note on these parameters: In a lognormal distribution, the parameters `meanlog` and `sdlog` describe the underlying normal distribution on the log scale, NOT the mean and standard deviation of the observed reaction times. If we want RTs centered around 250 ms, we set `meanlog` = log(250) because the median of a lognormal is `exp(meanlog)`---so this choice makes the median RT about 250 ms. The `sdlog` parameter controls the amount of skew on the log scale: typical behavioral data are well-modeled by `sdlog` values between about 0.3 and 0.5. Using `sdlog` = log(20) would be incorrect, because \`sdlog already represents variability on the log scale; taking the log of a raw-scale SD would produce unrealistically long-tailed RTs spanning thousands of milliseconds. You don't need to understand all of these details, but I realize it could be confusing and so wanted to include this explanation.

```{r}
# Helper: shifted lognormal RTs (t0 + LogNormal(meanlog, sdlog))
r_shifted_lognorm <- function(n, t0, meanlog, sdlog) {
  t0 + rlnorm(n, meanlog = meanlog, sdlog = sdlog)
}
```

```{r}
#| label: lognormal-single
# Here's the basic way you could simulate RTs and their logged RTs
rt_df <- tibble(
  rt = r_shifted_lognorm(500, t0 = 300, meanlog = log(250), sdlog = .35)
) |>
  mutate(log_rt = log(rt))
```

Now look at their relationship -- hint is to use qplot, or you can use ggplot. You'll need the `$` operator (e.g., `rt_df$rt`) to grab a particular column from a dataframe in base R.

```{r}
# TODO: P
qplot(rt_df$rt, rt_df$log_rt)
```

OK, now let's make some summaries. Use the summarize function foi calculate the mean, median, max, and sd of the rt distribution. Note that you don't have to make a new

```{r}
# TODO: summaries
rt_df_summary <- rt_df |>
  summarise(mean_rt = mean(rt), median_rt = median(rt), max_rt = max(rt), sd_rt = sd(rt))

head(rt_df_summary)
```

## D. Two conditions: valid vs invalid cue

Backstory. In a spatial attention task (think Posner cueing), each trial begins with a cue that is either valid (points to the upcoming target location) or invalid (points away). Valid cues help orient attention and typically speed responses; invalid cues slow responses. Reaction times (RTs) are right-skewed, as in the prior example. Let's try to simulate valid and invalid trials.

Add a **condition** factor. Suppose invalid cues slow responses by \~**40 ms** on average.

### Try it

```{r}
rt_df_valid_invalid <- tibble(
  rt_valid = r_shifted_lognorm(500, t0 = 300, meanlog = log(250), sdlog = log(50)), 
  rt_invalid = r_shifted_lognorm(500, t0 = 300, meanlog = log(290), sdlog = log(50))
) 
```

Use `pivot_longer` to make this a long dataframe, where `rt` is just one column, and you have `condition` in another column. Use the `?` to look at the arguments for the function.

```{r}
rt_df_valid_invalid_longer <- rt_df_valid_invalid |>
  pivot_longer(cols=c('rt_valid','rt_invalid'), values_to='rt', names_to='condition')
```

Now, use `group_by(condition)` before commuting your summaries in tidyverse -- you should see outputs grouped by condition.

```{r}

# TODO: group_by() condition and summarise mean_rt, sd_rt
valid_invalid_summary <- rt_df_valid_invalid_longer |>
  group_by(condition) |>
  summarise(mean_rt = mean(rt), sd_rt = sd(rt), n = n())

head(valid_invalid_summary)
```

Now, make some sort of visual of the two distributions Give the raw dataframe to ggplot, and use `geom_density` to plot the density (you can toggle `alpha` here to change the transparency). Use `fill=condition` within `aes` to specify that the two conditions should have different colors.

```{R}
## Use ggplot to make density plot of simulated data
ggplot(rt_df_valid_invalid_longer, aes(x=rt, fill = condition)) +
  geom_density(alpha = 0.5) +
  labs(title = "Cueing Cost as Shift in Distribution", x = "RT (ms)", y = "Density")
```

BONUS. Okay, so far you've been simulating "raw" data -- i.e., 500 trials of valid, and 500 trials of invalid cueing. Try simulating 10 different participants, where each participant completes 200 trials.

```{r}
# parameters for two conditions
t0_valid      <- 300
meanlog_valid <- log(250)
sdlog_valid   <- 0.35

t0_invalid      <- 320
meanlog_invalid <- log(260)
sdlog_invalid   <- 0.37

# start with an empty tibble
df_experiment <- tibble()


num_trials = 100
rt_upper_cutoff = 5000 # very slow rt
rt_lower_cutoff = 200 # very fast rt

# loop over participants (1–20)
for (i in 1:20) {
  print(i)
  # random baseline shift for this participant 
  baseline_shift <- rnorm(1, mean = 0, sd = 80)
  
  # simulate 200 trials (100 valid + 100 invalid)
  sim_subj <- tibble(
    participant  = i,
    condition = rep(c("valid", "invalid"), each = num_trials),
    trial     = rep(1:num_trials, times = 2),
    rt        = c(
      t0_valid   + baseline_shift + rlnorm(num_trials, meanlog = meanlog_valid, sdlog = sdlog_valid),
      t0_invalid + baseline_shift + rlnorm(num_trials, meanlog = meanlog_invalid, sdlog = sdlog_invalid)
    )
  ) |>
    filter(rt >= rt_lower_cutoff, rt <= rt_upper_cutoff) |>  # trim extremes
    mutate(log_rt = log(rt)) # take th elog
  
  # append to growing data frame
  df_experiment <- bind_rows(df_experiment, sim_subj)
}

```

```{r}
df_experiment_summary <- df_experiment %>%
  group_by(participant, condition) %>%
  summarize(mean_rt = mean(rt))
```

BONUS: Plot average RTs and 95 CIs over individual subjects. You cn resuse `stat_summary` arguments for the mean and CIs from above. Plot raw data points from each participant using `geom_point`.

```{r}
# Plot average RTs and 95 CIs over individual subjects
ggplot(df_experiment_summary, aes(x=condition, y=mean_rt, color=condition, fill=condition)) +
  geom_point(alpha=.6) + # plot individual subject means
  geom_line(aes(group=participant, alpha=.1), color='grey') + # connect data from each partiicpant
  stat_summary(fun = mean, geom = "point", size = 3) + # plot overall mean
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.1) + # plot CIs over people
  labs(x = "Condition", y = "Average RT", title = "RT by Simulated Cueing Condition") 
```